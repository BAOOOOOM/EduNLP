{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizer\n",
    "\n",
    "## 概述\n",
    "\n",
    "为了方便后续向量化表征试题，本模块提供题目文本的令牌化解析（Tokenization），即将题目文本转换成令牌序列。按照试题文本类型分为以下四部分：   \n",
    "\n",
    "1. 分句（sentence-tokenization）：将较长的文档切分成若干句子的过程称为“分句”。每个句子为一个“令牌”（token）。（待实现）    \n",
    "  \n",
    "\n",
    "\n",
    "2. 标记解析（text-tokenization）：一个句子（不含公式）是由若干“标记”按顺序构成的，将一个句子切分为若干标记的过程称为“标记解析”。每个标记为一个“令牌”（token）。    \n",
    "\n",
    "3. 公式解析（formula-tokenization）：理科类文本中常常含有公式。将一个符合 latex 语法的公式切分为标记字符列表的过程称为“公式解析”。每个标记字符为一个“令牌”（token）。  \n",
    "  \n",
    "4. 综合解析（item-tokenization）：将带公式的句子切分为若干标记的过程。每个标记为一个“令牌”（token）。    \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 标记解析\n",
    "\n",
    "先使用 `jieba` 分词工具得到分词序列，再过滤掉停用词 -  [stopwords](https://github.com/bigdata-ustc/EduNLP/blob/master/EduNLP/meta_data/sif_stopwords.txt)  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# 导入模块\n",
    "from EduNLP.SIF.tokenization.text import tokenize \n",
    "\n",
    "# 输入\n",
    "text = \"三角函数是基本初等函数之一\"\n",
    "# 输出\n",
    "print(tokenize(item))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['三角函数', '初等', '函数']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 公式解析\n",
    "切分出 latex 公式的每个标记符号。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# 导入模块\n",
    "from EduNLP.SIF.tokenization.formula import tokenize\n",
    "\n",
    "# 输入\n",
    "formula = \"\\\\frac{\\\\pi}{x + y} + 1 = x\"\n",
    "\n",
    "# 输出\n",
    "\n",
    "# 输出形式选择普通序列（linear）\n",
    "print('linear: ',tokenize(formula,method=\"linear\"))\n",
    "\n",
    "# 输出形式选择抽象语法分析树（ast）\n",
    "print('ast : ',tokenize(formula,method=\"ast\",return_type = \"list\", ord2token=False))\n",
    "\n",
    "# 输出形式选择抽象语法分析树（ast）且将公式变量名转换成 token \n",
    "print('ast & ord2token: ',tokenize(formula,method=\"ast\",return_type = \"list\", ord2token=True))\n",
    "\n",
    "# 输出形式选择抽象语法分析树（ast）且将公式变量名转换成带编号的 token\n",
    "print('ast & ord2token & var_numbering: ',tokenize(formula,method=\"ast\",return_type = \"list\", ord2token=True, var_numbering=True))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "linear:  ['\\\\frac', '{', '\\\\pi', '}', '{', 'x', '+', 'y', '}', '+', '1', '=', 'x']\n",
      "ast :  ['\\\\pi', '{ }', 'x', '+', 'y', '{ }', '\\\\frac', '+', '1', '=', 'x']\n",
      "ast & ord2token:  ['mathord', '{ }', 'mathord', '+', 'mathord', '{ }', '\\\\frac', '+', 'textord', '=', 'mathord']\n",
      "ast & ord2token & var_numbering:  ['mathord_con', '{ }', 'mathord_0', '+', 'mathord_1', '{ }', '\\\\frac', '+', 'textord', '=', 'mathord_0']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 综合解析\n",
    "\n",
    "标记解析 + 公式解析。特殊符号将转换成常量，例如：\n",
    "```python\n",
    "FIGURE_SYMBOL = \"[FIGURE]\" # $\\SIFChoice$\n",
    "QUES_MARK_SYMBOL = \"[MARK]\" # $\\FigureID{1}$\n",
    "```\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# 导入模块\n",
    "from EduNLP.Tokenizer import get_tokenizer\n",
    "\n",
    "# 输入\n",
    "item = {\n",
    "    \"如图来自古希腊数学家希波克拉底所研究的几何图形．此图由三个半圆构成，三个半圆的直径分别为直角三角形$ABC$的斜边$BC$, 直角边$AB$, $AC$.$\\bigtriangleup ABC$的三边所围成的区域记为$I$,黑色部分记为$II$, 其余部分记为$III$.在整个图形中随机取一点，此点取自$I,II,III$的概率分别记为$p_1,p_2,p_3$,则$\\SIFChoice$$\\FigureID{1}$\"\n",
    "}\n",
    "\n",
    "# 输出\n",
    "tokenizer = get_tokenizer(\"text\")\n",
    "tokens = tokenizer(item)\n",
    "next(tokens) "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['如图',\n",
       " '古希腊',\n",
       " '数学家',\n",
       " '希波',\n",
       " '克拉底',\n",
       " '研究',\n",
       " '几何图形',\n",
       " '此图',\n",
       " '三个',\n",
       " '半圆',\n",
       " '三个',\n",
       " '半圆',\n",
       " '直径',\n",
       " '直角三角形',\n",
       " 'ABC',\n",
       " '斜边',\n",
       " 'BC',\n",
       " '直角',\n",
       " 'AB',\n",
       " 'AC',\n",
       " '\\x08',\n",
       " 'igtriangleupABC',\n",
       " '三边',\n",
       " '围成',\n",
       " '区域',\n",
       " '记',\n",
       " 'I',\n",
       " '黑色',\n",
       " '记',\n",
       " 'II',\n",
       " '其余部分',\n",
       " '记',\n",
       " 'III',\n",
       " '图形',\n",
       " '中',\n",
       " '随机',\n",
       " '取',\n",
       " '一点',\n",
       " '此点',\n",
       " '取自',\n",
       " 'I',\n",
       " ',',\n",
       " 'II',\n",
       " ',',\n",
       " 'III',\n",
       " '概率',\n",
       " '记',\n",
       " 'p',\n",
       " '_',\n",
       " '1',\n",
       " ',',\n",
       " 'p',\n",
       " '_',\n",
       " '2',\n",
       " ',',\n",
       " 'p',\n",
       " '_',\n",
       " '3',\n",
       " '[MARK]',\n",
       " '[FIGURE]']"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}