{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. load and tokenize test_items"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from platform import processor\r\n",
    "from gensim import corpora,models\r\n",
    "# from collections import defaultdict\r\n",
    "import json\r\n",
    "from tqdm import tqdm\r\n",
    "from EduNLP.Pretrain import GensimWordTokenizer,train_vector\r\n",
    "from EduNLP.Vector import D2V\r\n",
    "from EduNLP.SIF.segment import seg\r\n",
    "from EduNLP.SIF.tokenization import tokenize\r\n",
    "import time\r\n",
    "\r\n",
    "output_file_head = \"test\"  # subject = english | liberal | science |all\r\n",
    "baseDir = \"E:/Workustc/lunadata/d2v\"\r\n",
    "# baseDir = \"/home/qlh/data_pretrain\"\r\n",
    "work_file_path = baseDir + \"/data/\" + output_file_head + \"_raw.json\"\r\n",
    "\r\n",
    "test_items = [{\"ques_content\":\"Human machine interface for lab abc computer applications\"},\r\n",
    "             {\"ques_content\": \"A survey of user opinion of computer system response time\"},\r\n",
    "             {\"ques_content\": \"The EPS user interface management system\"},\r\n",
    "             {\"ques_content\": \"System and human system engineering testing of EPS\"},\r\n",
    "             {\"ques_content\": \"Relation of user perceived response time to error measurement\"},\r\n",
    "             {\"ques_content\": \"The generation of random binary unordered trees\"},\r\n",
    "             {\"ques_content\": \"The intersection graph of paths in trees\"},\r\n",
    "             {\"ques_content\": \"Graph minors IV Widths of trees and well quasi ordering\"},\r\n",
    "             {\"ques_content\": \"Graph minors A survey\"}\r\n",
    "             ]\r\n",
    "\r\n",
    "def load_items():\r\n",
    "    for line in test_items:\r\n",
    "        yield line\r\n",
    "    # with open(work_file_path, 'r', encoding=\"utf-8\") as f:\r\n",
    "    #     for line in f:\r\n",
    "    #         yield json.loads(line)\r\n",
    "\r\n",
    "def data2Token():\r\n",
    "    # 线性分词，而不使用ast\r\n",
    "    tokenization_params = {\r\n",
    "        \"formula_params\": {\r\n",
    "            \"method\": \"linear\",\r\n",
    "        }\r\n",
    "    }\r\n",
    "    \r\n",
    "    token_items = []\r\n",
    "    count = 1\r\n",
    "    for item in tqdm(load_items(), \"sifing\"):\r\n",
    "        count = count + 1\r\n",
    "        # -------------------------------------------- # \r\n",
    "        # \"\"\"除文本、公式外，其他转化为特殊标记\"\"\"\r\n",
    "        seg_ret = seg(item[\"ques_content\"], symbol=\"gmas\")\r\n",
    "        token_item = tokenize(seg_ret, **tokenization_params)\r\n",
    "        # print(\"[my token] :\", token_item)\r\n",
    "\r\n",
    "        # -------------------------------------------- # \r\n",
    "        if token_item:\r\n",
    "            # print(\"[i] = \", count)\r\n",
    "            # print(\"[tokens] = \", token_item)\r\n",
    "            token_items.append(token_item.tokens)\r\n",
    "    print(\"[data2Token] finish ========================> num = \",len(token_items))\r\n",
    "    return token_items\r\n",
    "\r\n",
    "token_items = data2Token()\r\n",
    "token_items[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "sifing: 9it [00:00, 9017.85it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[data2Token] finish ========================> num =  9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "len(token_items)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. train and test model by 'bow'"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from EduNLP.Pretrain import train_vector\r\n",
    "#10 dimension with fasstext method\r\n",
    "train_vector(token_items, \"../../../data/d2v/gensim_luna_stem_tf_\", method=\"bow\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EduNLP, INFO model is saved to ../../../data/d2v/gensim_luna_stem_tf_bow.bin\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../../../data/d2v/gensim_luna_stem_tf_bow.bin'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from EduNLP.Vector import D2V\r\n",
    "\r\n",
    "d2v = D2V(\"../../../data/d2v/gensim_luna_stem_tf_bow.bin\", method = \"bow\")\r\n",
    "d2v(token_items[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. train and test model by 'tfidf'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from EduNLP.Pretrain import train_vector\r\n",
    "#10 dimension with fasstext method\r\n",
    "train_vector(token_items, \"../../../data/d2v/gensim_luna_stem_tf_\", method=\"tfidf\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EduNLP, INFO model is saved to ../../../data/d2v/gensim_luna_stem_tf_bow.bin\n",
      "EduNLP, INFO model is saved to ../../../data/d2v/gensim_luna_stem_tf_tfidf.bin\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../../../data/d2v/gensim_luna_stem_tf_tfidf.bin'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from EduNLP.Vector import D2V\r\n",
    "\r\n",
    "d2v = D2V(\"../../../data/d2v/gensim_luna_stem_tf_tfidf.bin\", method = \"tfidf\")\r\n",
    "d2v(token_items[0])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'TfidfLoader' object has no attribute '_filepath'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4c70d86321ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mEduNLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mD2V\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0md2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD2V\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../../data/d2v/gensim_luna_stem_tf_tfidf.bin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"tfidf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0md2v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\workustc\\edunlp\\workmaster\\edunlp\\EduNLP\\Vector\\gensim_vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath, method)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tfidf\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown method: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\workustc\\edunlp\\workmaster\\edunlp\\EduNLP\\Vector\\gensim_vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfidf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# 'tfidf' model shold be used based on 'bow' model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mdictionary_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"(.*)tfidf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"\\1bow\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfLoader' object has no attribute '_filepath'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}