{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load and tokenize test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MySoftwares\\Anaconda\\envs\\data\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "sifing: 9it [00:00, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data2Token] finish ========================> num =  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import processor\n",
    "from gensim import corpora,models\n",
    "# from collections import defaultdict\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from EduNLP.Pretrain import GensimWordTokenizer,train_vector\n",
    "from EduNLP.Vector import D2V\n",
    "from EduNLP.SIF.segment import seg\n",
    "from EduNLP.SIF.tokenization import tokenize\n",
    "import time\n",
    "\n",
    "output_file_head = \"test\"  # subject = english | liberal | science |all\n",
    "baseDir = \"E:/Workustc/lunadata/d2v\"\n",
    "# baseDir = \"/home/qlh/data_pretrain\"\n",
    "work_file_path = baseDir + \"/data/\" + output_file_head + \"_raw.json\"\n",
    "\n",
    "test_items = [{\"ques_content\":\"Human machine interface for lab abc computer applications\"},\n",
    "             {\"ques_content\": \"A survey of user opinion of computer system response time\"},\n",
    "             {\"ques_content\": \"The EPS user interface management system\"},\n",
    "             {\"ques_content\": \"System and human system engineering testing of EPS\"},\n",
    "             {\"ques_content\": \"Relation of user perceived response time to error measurement\"},\n",
    "             {\"ques_content\": \"The generation of random binary unordered trees\"},\n",
    "             {\"ques_content\": \"The intersection graph of paths in trees\"},\n",
    "             {\"ques_content\": \"Graph minors IV Widths of trees and well quasi ordering\"},\n",
    "             {\"ques_content\": \"Graph minors A survey\"}\n",
    "             ]\n",
    "\n",
    "def load_items():\n",
    "    for line in test_items:\n",
    "        yield line\n",
    "    # with open(work_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    #     for line in f:\n",
    "    #         yield json.loads(line)\n",
    "\n",
    "def data2Token():\n",
    "    # 线性分词，而不使用ast\n",
    "    tokenization_params = {\n",
    "        \"formula_params\": {\n",
    "            \"method\": \"linear\",\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    token_items = []\n",
    "    count = 1\n",
    "    for item in tqdm(load_items(), \"sifing\"):\n",
    "        count = count + 1\n",
    "        # -------------------------------------------- # \n",
    "        # \"\"\"除文本、公式外，其他转化为特殊标记\"\"\"\n",
    "        seg_ret = seg(item[\"ques_content\"], symbol=\"gmas\")\n",
    "        token_item = tokenize(seg_ret, **tokenization_params)\n",
    "        # print(\"[my token] :\", token_item)\n",
    "\n",
    "        # -------------------------------------------- # \n",
    "        if token_item:\n",
    "            # print(\"[i] = \", count)\n",
    "            # print(\"[tokens] = \", token_item)\n",
    "            token_items.append(token_item.tokens)\n",
    "    print(\"[data2Token] finish ========================> num = \",len(token_items))\n",
    "    return token_items\n",
    "\n",
    "token_items = data2Token()\n",
    "token_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 2. train and test model by 'bow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EduNLP, INFO model is saved to ../../../data/d2v/gensim_luna_stem_tf_bow.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../../data/d2v/gensim_luna_stem_tf_bow.bin'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EduNLP.Pretrain import train_vector\n",
    "#10 dimension with fasstext method\n",
    "train_vector(token_items, \"../../../data/d2v/gensim_luna_stem_tf_\", method=\"bow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EduNLP.Vector import D2V\n",
    "\n",
    "d2v = D2V(\"../../../data/d2v/gensim_luna_stem_tf_bow.bin\", method = \"bow\")\n",
    "d2v(token_items[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. train and test model by 'tfidf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EduNLP, INFO model is saved to ../../../data/d2v/gensim_luna_stem_tf_bow.bin\n",
      "EduNLP, INFO model is saved to ../../../data/d2v/gensim_luna_stem_tf_tfidf.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../../data/d2v/gensim_luna_stem_tf_tfidf.bin'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EduNLP.Pretrain import train_vector\n",
    "#10 dimension with fasstext method\n",
    "train_vector(token_items, \"../../../data/d2v/gensim_luna_stem_tf_\", method=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.4104025153454256),\n",
       " (1, 0.4104025153454256),\n",
       " (2, 0.4104025153454256),\n",
       " (3, 0.2809349364094278),\n",
       " (4, 0.2809349364094278),\n",
       " (5, 0.4104025153454256),\n",
       " (6, 0.4104025153454256)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EduNLP.Vector import D2V\n",
    "\n",
    "d2v = D2V(\"../../../data/d2v/gensim_luna_stem_tf_tfidf.bin\", method = \"tfidf\")\n",
    "d2v(token_items[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
